{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Odkomentuj i wykonaj ten kod, jeżeli masz problemy z zaimportowaniem bibliotek.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.24.2\n",
    "# !pip install seaborn==0.12.2\n",
    "# !pip install pandas==1.5.3\n",
    "# !pip install scikit-learn==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_web_local_paths = {\n",
    "    'https://raw.githubusercontent.com/Kolo-Naukowe-Data-Science-PW/PoweR_2023/main/01_feature_engineering/Python/data/census_01.csv': 'census_data_01.csv',\n",
    "    'https://raw.githubusercontent.com/Kolo-Naukowe-Data-Science-PW/PoweR_2023/main/01_feature_engineering/Python/data/census_02.csv': 'census_data_02.csv',\n",
    "    'https://raw.githubusercontent.com/Kolo-Naukowe-Data-Science-PW/PoweR_2023/main/01_feature_engineering/Python/data/census_03.csv': 'census_data_03.csv',\n",
    "    'https://raw.githubusercontent.com/Kolo-Naukowe-Data-Science-PW/PoweR_2023/main/01_feature_engineering/Python/data/census_04.csv': 'census_data_04.csv'\n",
    "}\n",
    "\n",
    "for web_path, local_path in df_web_local_paths.items():\n",
    "    tmp = pd.read_csv(web_path)\n",
    "    tmp.to_csv(local_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('census_data_01.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoweR\n",
    "\n",
    "# Część I: Feature engineering\n",
    "*Prowadzący: Dawid Płudowski*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podstawowe pojęcia \n",
    "\n",
    "* **ramka danych** - dane w postaci tabeli (u nas `df`)\n",
    "\n",
    "* **obserwacja** - wiersz ramki danych; zawiera informacje o pojdeynczym wydarzeniu/fakcie (`np. df.iloc[1]`)\n",
    "\n",
    "* **zmienna objaśniana** - kolumna ramki danych, którą chcemy przewidywać za pomocą modelu uczenia maszynowego (u nas `df.loc[:, 'income']`)\n",
    "\n",
    "* **zmienne objaśniające** - kolumny tabeli, na podstawie których chcemy przewidywać zmienną objaśniającą (np. `df['education']`)\n",
    "\n",
    "* **wartość brakująca** - komórka tabeli, która nie ma wartości; potocznie `null`, w Pythonie `None` (czasami kodowana za pomocą wartości specjalnych)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wartości brakujące"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szukamy w zbiorze danych wartości, które mogą kodować brak danych. Jak mogą wyglądać?\n",
    "\n",
    "Zmienne kategoryczne:\n",
    "* znaki zapytania\n",
    "* puste napisy\n",
    "* słowa-klucze, np. '*unknown*' , '*blank*'\n",
    "\n",
    "Zmienne numeryczne:\n",
    "* wartości spoza możliwego zakresu (np. 1000 w zmiennej `age`)\n",
    "* wartość ujemna, jeżeli cała reszta jest dodatnia\n",
    "* liczby, które często są stosowane do kodowania nulli, np. -999, 999\n",
    "\n",
    "Po znalezieniu wartości, która reprezentuje wartość brakującą powinniśmy ją zakodować jako `None`, żeby później wygodnie z nią pracować.\n",
    "\n",
    "**Uwaga**: biblioteka `pandas` oraz `numpy` posiadają własne oznaczenia na braki danych (`pd.NA`, `np.nan`, `np.NaN`), które nie są tym samym!\n",
    "\n",
    "Artykuł o narzędziach do automatycznej analizy danych: [www.analyticsvidhya.com](https://www.analyticsvidhya.com/blog/2021/04/top-python-libraries-to-automate-exploratory-data-analysis-in-2021/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# przydatne funkcje\n",
    "\n",
    "df['age'].hist() # wyświetla histogram wartości\n",
    "df['occupation'].unique()\n",
    "df[df['final_pop_weight'] < 0] # sposób na filtrowanie ramki danych\n",
    "df['age'].mask(df['age'] > 80, None) # zamienia wartości, ktore spełniają warunek na None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1. szukanie wartości brakujących w zbiorze `Census`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final_pop_weight</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>work_hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>42128.866677</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>College</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>primary school</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>College</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  final_pop_weight       education marital_status  \\\n",
       "0   90         ?             77053      Highschool        Widowed   \n",
       "1   82   Private            132870      Highschool        Widowed   \n",
       "2   66         ?            186061         College        Widowed   \n",
       "3   54   Private            140359  primary school       Divorced   \n",
       "4   41   Private            264663         College      Separated   \n",
       "\n",
       "          occupation   race     sex  capital_gain  work_hours_per_week  \\\n",
       "0                  ?  White  Female      0.000000                   40   \n",
       "1    Exec-managerial  White  Female  42128.866677                   18   \n",
       "2                  ?  Black  Female      0.000000                   40   \n",
       "3  Machine-op-inspct  White  Female      0.000000                   40   \n",
       "4     Prof-specialty  White  Female      0.000000                   40   \n",
       "\n",
       "  native_country  income  \n",
       "0  United-States     1.0  \n",
       "1  United-States     1.0  \n",
       "2  United-States     1.0  \n",
       "3  United-States     1.0  \n",
       "4  United-States     1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>final_pop_weight</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>work_hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32538.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>110.297902</td>\n",
       "      <td>1.895912e+05</td>\n",
       "      <td>16011.616137</td>\n",
       "      <td>39.927121</td>\n",
       "      <td>0.759112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>252.778636</td>\n",
       "      <td>1.056550e+05</td>\n",
       "      <td>36868.108854</td>\n",
       "      <td>14.344230</td>\n",
       "      <td>0.427629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>-1.230000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.177670e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.783120e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.369130e+05</td>\n",
       "      <td>11911.240526</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>423844.271600</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  final_pop_weight   capital_gain  work_hours_per_week  \\\n",
       "count  32561.000000      3.256100e+04   32561.000000         32561.000000   \n",
       "mean     110.297902      1.895912e+05   16011.616137            39.927121   \n",
       "std      252.778636      1.056550e+05   36868.108854            14.344230   \n",
       "min       17.000000     -1.230000e+02       0.000000            -1.000000   \n",
       "25%       28.000000      1.177670e+05       0.000000            38.000000   \n",
       "50%       39.000000      1.783120e+05       0.000000            40.000000   \n",
       "75%       51.000000      2.369130e+05   11911.240526            45.000000   \n",
       "max      999.000000      1.484705e+06  423844.271600           149.000000   \n",
       "\n",
       "             income  \n",
       "count  32538.000000  \n",
       "mean       0.759112  \n",
       "std        0.427629  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktywność 1.\n",
    "Czas: ok. 5min\n",
    "\n",
    "Szukamy kolejnych braków danych w ramce i oznaczamy je jako `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na Twój kod :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputacja danych\n",
    "\n",
    "Udało nam się zidentyfikować nulle w naszej ramce danych. Teraz musimy je uzupełnić, aby można na nich ćwiczyć model. Rodzaje braków danych możemy podzielić na następujące kategorie:\n",
    "* Missing completely at random (**MCAR**)\n",
    "* Missing at random (**MAR**)\n",
    "* Missing not at random (nonignorable)\n",
    "\n",
    "W przypadku naszych danych możemy założyć, że braki nie niosą ze sobą żadnej istotnej informacji (MCAR) i możemy je uzupełnić w konwencjonalny sposób. W przypadku danych numerycznych uzupełnimy je średnią, natomiast dane kategoryczne uzupełnimy najczęściej występującą wartością. Dlaczego taka strategia ma sens:\n",
    "* jeżeli nic nie wiemy o naszym braku to, o ile pochodzi on z tego samego rozkładu co pozostałe dane, najmniej pomylimy się estymując go średnią/najczęściej występującą wartością\n",
    "\n",
    "Artykuł o rodzajach braków danych: [displayr.com/different-types-of-missing-data/](https://www.displayr.com/different-types-of-missing-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# przydatne funkcje\n",
    "imputer_mean = SimpleImputer(missing_values=np.nan, strategy='mean') # zamienia NaN na średnią\n",
    "imputer_mod = SimpleImputer(missing_values=np.nan, strategy='most_frequent') # zamienia NaN na najczęściej występującą wartość\n",
    "\n",
    "imputer_mean.fit_transform(df[['capital_gain']]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.\n",
    "Imputujemy braki danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "new_age = imputer_mean.fit_transform(df[[\"age\"]])\n",
    "df['age'] = new_age"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktywność 2.\n",
    "Czas: ok. 3 min\n",
    "\n",
    "Kontynuujemy uzupełniane nulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na twój kod :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Szukanie outlierów\n",
    "\n",
    "Nasze dane są już kompletne, jednak niektóre z nich, nawet jeżeli prawdziwe, mogą utrudnić modelowi proces uczenia. Dlaczego tak się dzieje?\n",
    "\n",
    "### Wartości odstające \n",
    "Nasz zbiór danych zawiera pojedyncze obseracje, które zaburzają przewidywanie.\n",
    "\n",
    "**Przykład**:\n",
    "\n",
    "Dysponujemy informacją o zawodzie (lub jego braku) grupy osób i chcemy przewidywać na podstawie tego wielkość ich oszczędności. Logiczne jest, że osoba bezrobotna powinna mieć ich raczej mniej niż np. data scientist. Jeżeli jednak w naszej grupie osób na 1.000 bezrobotnych jeden jest miliarderem (np. odziedziczył te pieniądze) to czy taka informacja nie jest myląca? Niektóre modele będą próbować uogólnić ten fakt i nauczą się, że skoro 999 osób z danej grupy ma 0zł oszczędności, a jedna 1.000.000.000zł to średnio osoba bezrobotna ma 1.000.000zł oszczędności.\n",
    "\n",
    "Z drugiej strony, usunięcie podpopulacji miliarderów z danych sprawi, że nasz model nigdy nie nauczy się jak ich przewidywać.\n",
    "\n",
    "### Generalizacja\n",
    "\n",
    "Nigdy nie dysponujemy kompletnymi danymi o danym zjawisku, dlatego też chcielibyśmy, aby nasz model generalizował fakty. Tak jak w powyższym przykładzie, powiedzielibyśmy: \"oszczędności ludzi bezrobotnych różnią się w zależności od innych czynników, ale generalnie są niskie\".\n",
    "\n",
    "### Małe grupy\n",
    "\n",
    "Czasami dana cecha (np. bycie noblistą z fizyki) jest tak rzadka, że nie mamy wystarczająco dużo obserwacji, które by ją posiadały, aby móc model mógł na jej podstawie wyciągnąc wniosków. Czasami decydujemy się, aby takie małe podpopulacje łączyć ze sobą, w szczególności jeżeli podejrzewamy, że nie wykazują znaczących róznic (np. nobliści z fizyki i ekonomii). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3. \n",
    "\n",
    "Szukamy i usuwamy outliery ze zbioru danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktywność 3.\n",
    "Czas: ok. 10min\n",
    "\n",
    "Kontynuujemy poszukiwania outlierów. Istnieją różne strategie radzenia sobie z nimi, my wykorzystamy najprostszą, to znaczy \"na oko\" ;) Użyjemy w tym celu wykresów, aby zdecydować, gdzie \"obciąć\" wartości numeryczne oraz jak zgrupować wartości kategoryczne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./census_data_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# przydatne funkcje\n",
    "sns.countplot(data=df, x='education') # wykres dla zmiennych kategorycznych\n",
    "sns.histplot(data=df, x='age', bins=100) # wykres dla zmiennych numerycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na Twój kod :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodowanie zmiennych kategorycznych\n",
    "\n",
    "Kolejnym krokiem w przygotowywaniu naszych danych jest zamiana zmiennych kategorycznych na liczbowe. Dlaczego taka zmiana jest potrzebna?\n",
    "* modele uczenia maszynowego to skomplikowane funkcje matematyczne - potrzebują liczb jako argumentów\n",
    "* czasami zmienne kateogryczne mają swój naturalny porządek (np. mały - średni - duży); odpowiednie kodowanie dostarczy modelowi informacji o tym porządku\n",
    "* popularne biblioteki do uczenia maszynowego w **Pythonie** (np. używany na tych warsztatach `sklearn`) zwykle nie wspierają wartości kategorycznych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Przydatne funkcje:\n",
    "\n",
    "df[\"education\"].unique()  # tabela[\"zmienna\"].unique() ~ zwraca unikalne wartości w danej kolumnie\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False) # \n",
    "new_columns = onehot_encoder.fit_transform(df[[\"education\"]]) # zwraca zakodowaną kolumnę\n",
    "new_columns_names = onehot_encoder.get_feature_names_out() # zwraca nazwy \n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    # categories=[['cat_01', 'cat_02', 'cat_03', '...']]\n",
    "    ) # param categories ustala porządek kodowania\n",
    "ordinal_encoder.fit_transform(df[[\"education\"]])\n",
    "ordinal_encoder.get_feature_names_out()\n",
    "\n",
    "df_temp = pd.DataFrame(data=new_columns, columns=new_columns_names) # tworzy nową tabelę\n",
    "\n",
    "df.drop(columns=[\"education\"]) # usuwa z tabeli kolumnę\n",
    "df.join(df_temp) # łączy dwie tabele "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4. kodowanie zbioru `Census`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final_pop_weight</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>work_hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77053</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>628.643586</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186061</td>\n",
       "      <td>College</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>primary school</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>College</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age workclass  final_pop_weight       education marital_status  \\\n",
       "0  90.0       NaN             77053      Highschool        Widowed   \n",
       "1  82.0   Private            132870      Highschool        Widowed   \n",
       "2  66.0       NaN            186061         College        Widowed   \n",
       "3  54.0   Private            140359  primary school       Divorced   \n",
       "4  41.0   Private            264663         College      Separated   \n",
       "\n",
       "          occupation   race     sex  capital_gain  work_hours_per_week  \\\n",
       "0                  ?  White  Female      0.000000                   40   \n",
       "1    Exec-managerial  White  Female    628.643586                   18   \n",
       "2                  ?  Black  Female      0.000000                   40   \n",
       "3  Machine-op-inspct  White  Female      0.000000                   40   \n",
       "4     Prof-specialty  White  Female      0.000000                   40   \n",
       "\n",
       "  native_country  income  \n",
       "0  United-States     1.0  \n",
       "1  United-States     1.0  \n",
       "2  United-States     1.0  \n",
       "3  United-States     1.0  \n",
       "4  United-States     1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktywność 4.\n",
    "Czas: ok. 7min\n",
    "\n",
    "Kodujemy pozostałe zmienne kategoryczne. Metodę kodowania (`OrdinalEncoder`, `OneHotEncoder`) wybieramy zgodnie z poznanymi wcześniej praktykami. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./census_data_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na twój kod :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformacje zmiennych\n",
    "\n",
    "Mamy już ramkę danych posiadającą tylko zmienne liczbowe, bez nulli i z obciętymi outlierami. Ramka w takiej postaci jest już gotowa do użycia jej w celu uczenia modelu. Mimo to, nadal może nasze dane ulepszyć.\n",
    "\n",
    "#### Po co transformujemy zmienne?\n",
    "\n",
    "* niektóre modele uczenia maszynowego powstały w oparciu o matematyczne założenia jakie powinny spełniać dane. W szczególności, częstym założeniem jest to, że pojdencze zmienne pochodzą z rozkładu normalnego\n",
    "* zrzutowanie zmiennych do tego samego przedziału lub kształu pozwala nam później łatwo porównywać ich znaczenie w procesie *XAI* ([artykuł o metodach XAI](https://ema.drwhy.ai/))\n",
    "\n",
    "#### Których zmiennych nie transformujemy?\n",
    "\n",
    "* zmienne, które są zakodowanymi wartościami kategorycznymi nie potrzebują kolejnych transformacji.\n",
    "\n",
    "![rozkład normalny](https://cdn.corporatefinanceinstitute.com/assets/normal-distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_transformer = QuantileTransformer(output_distribution='normal')\n",
    "df['age'] = normal_transformer.fit_transform(df[['age']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktywność 5.\n",
    "Czas: ok. 5min\n",
    "\n",
    "Przeprowadzamy transformacje zmiennych do rozkładu normalnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./census_data_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na Twój kod :) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktywność dodatkowa - zaawansowane kodowanie zmiennych kategorycznych\n",
    "\n",
    "Przechodzimy do zbioru **taxis**. Poniżej znajduje się kod, który mapuje dni tygodnia na liczby od 0 do 6. Chcemy je zakodować jako zmienną cykliczną; aby to zrobić wykonamy następujące kroki:\n",
    "* przeskalujmy zmienne do zakresu $[0, 2\\pi]$, np. mnożąc liczby przez $\\frac{2\\pi}{6}$ (dlaczego przez 6?)\n",
    "* obliczymy $\\sin$ i $\\cos$ dla tak przeskalowanych zmiennych\n",
    "* na koniec wystarczy dodać kolumny z $\\sin$ i $\\cos$ do tabeli i usunąć starą zmienną reprezentującą dni tygodnia :)\n",
    "\n",
    "Poniżej znajduje się kod, który zwizualizuje twoje wyniki, sprawdź, czy wygenerowane punkty znajdują się na okręgu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "      <th>passengers</th>\n",
       "      <th>distance</th>\n",
       "      <th>fare</th>\n",
       "      <th>tip</th>\n",
       "      <th>tolls</th>\n",
       "      <th>total</th>\n",
       "      <th>color</th>\n",
       "      <th>payment</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>pickup_borough</th>\n",
       "      <th>dropoff_borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-03-23 20:27:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.95</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Lenox Hill West</td>\n",
       "      <td>UN/Turtle Bay South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-04 16:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.30</td>\n",
       "      <td>yellow</td>\n",
       "      <td>cash</td>\n",
       "      <td>Upper West Side South</td>\n",
       "      <td>Upper West Side South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-27 18:00:25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.16</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>West Village</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-10 01:49:51</td>\n",
       "      <td>1</td>\n",
       "      <td>7.70</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.95</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Hudson Sq</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-03-30 13:37:14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.16</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.40</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Midtown East</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup             dropoff  passengers  distance  fare   tip  tolls  total  \\\n",
       "0       5 2019-03-23 20:27:24           1      1.60   7.0  2.15    0.0  12.95   \n",
       "1       0 2019-03-04 16:19:00           1      0.79   5.0  0.00    0.0   9.30   \n",
       "2       2 2019-03-27 18:00:25           1      1.37   7.5  2.36    0.0  14.16   \n",
       "3       6 2019-03-10 01:49:51           1      7.70  27.0  6.15    0.0  36.95   \n",
       "4       5 2019-03-30 13:37:14           3      2.16   9.0  1.10    0.0  13.40   \n",
       "\n",
       "    color      payment            pickup_zone           dropoff_zone  \\\n",
       "0  yellow  credit card        Lenox Hill West    UN/Turtle Bay South   \n",
       "1  yellow         cash  Upper West Side South  Upper West Side South   \n",
       "2  yellow  credit card          Alphabet City           West Village   \n",
       "3  yellow  credit card              Hudson Sq         Yorkville West   \n",
       "4  yellow  credit card           Midtown East         Yorkville West   \n",
       "\n",
       "  pickup_borough dropoff_borough  \n",
       "0      Manhattan       Manhattan  \n",
       "1      Manhattan       Manhattan  \n",
       "2      Manhattan       Manhattan  \n",
       "3      Manhattan       Manhattan  \n",
       "4      Manhattan       Manhattan  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxis = sns.load_dataset(\"taxis\")\n",
    "df_taxis['pickup'] = pd.to_datetime(df_taxis['pickup']).dt.weekday\n",
    "df_taxis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# przydatne funkcje i atrubuty\n",
    "\n",
    "np.pi # wartość pi\n",
    "np.cos(2) \n",
    "np.sin(2 * np.pi)\n",
    "\n",
    "df_taxis['pickup'] * 2 * np.pi - 5 # możemy mnożyć całą kolumnę przez stałą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na Twoje rozwiązanie :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod do wizualizacji\n",
    "\n",
    "sns.scatterplot(x=cos_column, y=sin_column)\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlim(-2, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aktywność dodatkowa - budowa pipelinów\n",
    "\n",
    "Zrobiliśmy w trakcie tych warsztatów wiele modyfikacji naszych danych. Chcielibyśmy posiadać narzędzie, które te wszystkie zmiany wykona w ramach jednej funkcji, np. gdybyśmy chcieli analogiczne zmiany zaaplikować do zbioru testowego albo nowo dostarczonych danych. Funkcje, które realizuje ten cel to tzw. `pipeline`'y. W ramach ostatniej sekcji naszych warsztatów spróbujemy zaimplementować klasę, która wykona wszystkie wcześniej wspomniane transformacje za pomocą jednej metody `.transform(dataset)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przydatne linki\n",
    "* [`miceforest`](https://pypi.org/project/miceforest/)\n",
    "* [`pycircural`](https://towardsdatascience.com/introducing-pycircular-a-python-library-for-circular-data-analysis-bfd696a6a42b)\n",
    "* [`feature-engine`](https://feature-engine.trainindata.com/en/latest/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b53503e775af5719651d572845313f19bfaf3340c034229faed23b2f7437e58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
